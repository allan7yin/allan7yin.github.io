## Topic 7: Context-free Grammars

To put it in brief terms, context-free grammar (CFG) is is a formalism for describing the syntax of a language. It consists of a set of production rules that define how to generate valid sentences in the language.

**Recall: We finished looking at regular languages in the previous model.**

- Remember the definition of what a regular language is: a type of formal language that be described by a regular expression or a DFA. Regular languages have more simplistic structure and a more limited expressive power than **context-free languages,** which is what we will consider moving forward. They are often used to describe simple patterns in strings, such as matching a sequence of characters, checking whether a string starts or ends with a certain substring, or detecting repetitions.

  

Recall that the basic compilation steps, from a **high-level language** to a **low-level language** are:

1. Scanning: Identify the tokens ==**DONE**==
2. Syntactic Analysis: Checking order of tokens ==**THIS LECTURE**==
3. Semantic Analysis: Create symbol tale and perform type checking ==**LATER**==
4. Code generation ==**LATER**==

  

There is one crucial limitation to Regular Languages when it comes to syntax. The **Key Problem** is that we need a more powerful tool than regular languages / DFAs / NFAs to check syntax. For example, something like ensuring there are balanced parentheses or braces in a program:

```Assembly
(((()))) 

{
	{
	}
}
```

To demonstrate the limitations of Regular Languages, consider the following example:

> Create a DFA that recognizes the language `_L = {w: the number of a’s in w is equal to the number of b’s in w}_` over the `alphabet {a,b}`.

Now, this is a relatively easy task to do, if the difference in the number of **a’s** and **b’s** is fixed, say 2, which is shown in the DFA below:

![[Screenshot_2023-02-17_at_7.19.02_PM.png]]

However, it is impossible if the potential difference is unbounded. This demonstrates one of the shortcomings of DFA’s and Regular Languages. DFA’s are good at tracking a finite number of things, for instance strings with 3 b’s in a row. However, when checking syntax, we often need an unbounded stack to track whatever it is we are counting (e.g. The potential number of nested parentheses is unbounded, will need unbounded stack to track left and right parentheses.

![[Screenshot_2023-02-17_at_7.33.30_PM.png]]

Recall the diagram above. The above implies that:

- all **Finite Languages** are **Regular Languages**
- all **Regular Languages** are **Context-free languages**

  

**⇒ Specifying a Valid Structure**

English has rules that guide **sentence structure**. For example, consider the following:

![[Screenshot_2023-02-18_at_3.55.22_PM.png]]

These rules have 2 types of components:

1. **==Terminals==**
    1. Components that appear in the output e.g. **==the, dog, barks==**
2. **==Non-terminals / Variables==**
    1. These specify the format of the sentence. These components do not appear in the output. So, in the above image, things like the ==**<subj phrase><verb>**== and **==<article><noun>==** are considered non-terminals/variables.

We can expand a **==non-terminal==** into zero or more **terminals, non-terminals, or both.** Consider the following example:

![[Screenshot_2023-02-18_at_6.15.07_PM.png]]

Just like in math, we justify each step with whatever rule we have used. Here is an example of a **CFG**:

![[Screenshot_2023-02-18_at_6.19.34_PM.png]]

Can think of the arrows as similar to equal signs. The above are rules, and rules will always follow the same set of format:

- Rules **always have** a **single** ==**non-terminal**== on the LHS
- Rules **can have** a mixture of ==**terminals**==**,** ==**non-terminals**==**,** or **empty**, on the RHS
- We can derive the word “accb” in the language generated by the above grammar **G.**
    - L(G), since **derive** accb from G
- Use → for rules, and ⇒ for derivations

In the above, ==**S**== is usually used to denote the start symbol. So, we get: ==**S ⇒ aSb ⇒ aDb ⇒ acDb ⇒ accDb ⇒ accb**====.== Derivations simply apply a sequence of rules by replacing non-terminals in the string using rules for the grammar.

![[Screenshot_2023-02-18_at_6.26.49_PM.png]]

![[Screenshot_2023-02-18_at_6.28.10_PM.png]]

When deriving, we always begin with start symbol, and rewrite one ==**non-terminal**== with one rule, one at a time, until there are no ==**non-terminal**== remaining, and only **==terminals==** left.

  

**⇒ Some Informal Definitions**

- ==**G**==**:** a context free grammar
- ==**L(G)**==**:** The language (set of words) specified by G
- ==**Word**==**:** a sequence of terminals that can be derived by applying the rules of the CFG
- ==**Derivation**==**:** Starting with the start symbol, apply a sequence of rules until there are no more **non-terminals**
- ==**Production Rules (AKA Re-write rules)**==**:** These are just the “rules” seen above. They capture
    - Union
    - Concatenation
    - Recursion (which is strictly more powerful than repetition)

Consider the above rules again:

![[Screenshot_2023-02-18_at_6.19.34_PM.png]]

Rules **(1) (2)** represent union, as together, they imply that the language generated by the symbol ==**S**==, is the union of the languages generated by ==**a**====**S**====**b**==, and ==**D**==. Quite intuitively, rules **(1) (3)** are recursive, as the ==**non-terminal**== is found both in the LHS, and RHS. Here is a short comparison between CFG and Regular Languages:

![[Screenshot_2023-02-18_at_7.32.24_PM.png]]

> So, what is this **unbounded stack** that we are mentioning anyways? An unbounded stack is a data structure used in the parsing process, to keep track of of the symbols that have been derived from the grammar. It is “unbounded” as it can hold a arbitrary number of symbols.

> The unbounded stack is a data structure that the parser uses to store the symbols it has derived so far. Each time the parser applies a production rule to a symbol, it pushes the RHS symbols of the rule onto the stack. If the parser later determines that this derivation is invalid, it can backtrack by popping symbols off the stack until it reaches a point where it can apply a different production rule.

  

**⇒ CFG Components - Informal Definition**

- ==**N**==**:** a finite set of non-terminals
    - Never appear at the end of a derivation
- ==**T**==**:** a finite set of terminals
    - May appear at the end of a derivation
- ==**P**==**:** a finite set of of production rules in the form of ==**A → B**== where:
    - **A** is a non-terminal
    - **B** is a repetition of terminals and non-terminals
- ==**S**==**:** S is the start symbol, it is a ==**S ∈ N**==
    - By convention, starts on the LHS of the first rule

  

> **Consider the following example of using the above notation:**

![[Screenshot_2023-02-18_at_7.39.05_PM.png]]

![[Screenshot_2023-02-18_at_7.39.35_PM.png]]

![[Screenshot_2023-02-18_at_7.44.15_PM.png]]

![[Screenshot_2023-02-18_at_7.44.23_PM.png]]

Now, let’s take a look at some derivation details.

- ==**Left-recursion**==**:** A non-terminal is on both the LHS and RHS of a rule and it is the **leftmost symbol** of the RHS
- ==**right-recursion**==**:** a non-terminal is on both the LHS and RHS of a rule and it is the **rightmost symbol** on the RHS

Here are some examples of these in action:

![[Screenshot_2023-02-18_at_8.23.45_PM.png]]

![[Screenshot_2023-02-18_at_8.24.02_PM.png]]

We will often use the two types together inside of the production rules. Let’s look at some examples.

  

**⇒ Example 1**

![[Screenshot_2023-02-18_at_9.44.05_PM.png]]

Now, let’s show the steps to derive certain words:

- ==**baa: S ⇒ bS ⇒ baSa ⇒ baa**==
- ==**aab: S ⇒ Sb ⇒ aSab ⇒ aab**==
- ==**babaaba: S ⇒ bS ⇒ baSa ⇒ babSa ⇒ babSba ⇒ babaSaba ⇒ babaaba**==

The case when we have the word **aba,** is special. This is because we have 2 ways of deriving this word:

- **S ⇒ aSa ⇒ aSba ⇒ aba**
- **S ⇒ aSa ⇒ abSa ⇒ aba**

When a grammar has this property, where there are multiple derivations for the same word, the grammar can be ==**ambiguous**== **(This is sort of similar to how we define unambiguous expressions in MATH239).**

  

**⇒ Example 2**

![[Screenshot_2023-02-18_at_9.52.40_PM.png]]

With these production rules, we can generated any binary string tat has no leading 0’s, other than the single 0 digit.

  

**⇒ Example 3**

![[Screenshot_2023-02-18_at_9.53.32_PM.png]]

Now, this one is a bit more interesting, as it presents something new. Here, **E** means arithmetic expression, **B** means generate a 0 or D, and **D** means generate binary number with a leading 1.

- **Derive “10 + 1”:**
    - **Rightmost derivation (i.e always expand the rightmost non-terminal first)**
        - Below is how we can do it.
            
            ![[Screenshot_2023-02-18_at_10.00.46_PM.png]]
            
    - **Leftmost derivation (i.e always expand the leftmost non-terminal first)**
        - We annotate above the arrows, to indicate which rule was used.

![[Screenshot_2023-02-18_at_9.59.21_PM.png]]

  

Currently, the notation ⇒ represents a rule being applied. When we do **⇒***, we are expressing the sequence of derivations from the begging symbol to the end. So, in the below, we want the parse tree for all derivations that occur from beginning symbol until the end:

![[Screenshot_2023-02-18_at_10.02.03_PM.png]]

Which is really the same thing as normal derivation, just visually more clear.

  

**⇒ Parse Trees**

- **Root:** the root node is the start symbol
- **Internal nodes:** these are the non-terminals
- **Children:** each internal node has children, which are given by a production rule
- **Leaf nodes:** are the terminals
- ==**Parse Trees**== can help us visualize ambiguous grammars

What does ambiguous mean though? As mentioned before, it is when there are multiple ways of deriving a string from a grammar. In general terms, ambuguouity refers to when something is unclear, like the sentence:

> **Allan was given a book by J. K. Rowling**

Was Allan given a book, physically, by Rowling? Or a book that was written by Rowling, or both! Computer languages are at risk of being ambiguous:

> **1 - 10 + 11**

Is the computer to interpret this as (1 - 10) + 11 or 1 - (10 + 11), or both?

  

In parse trees, the same string can have two different parse trees, implying there are 2 sequences of rules that can be applied to achieve one string. If this is possible for a grammar, then it is ==**ambiguous**==**,** as mentioned before.

![[Screenshot_2023-02-18_at_11.48.01_PM.png]]

**⇒ Processing Order in a Parse Tree**

Now, there are some implications that come with ambiguity. To understand those, we need to first look at how parse trees are processed. Parse trees are processed using a ==**post-order depth first**== traversal.

- ==**depth-first**==**:** visit the first child and all its descendants, before visiting the second child
- ==**post-order**==**:** process all the children before processing the parent

![[Screenshot_2023-02-19_at_11.27.29_AM.png]]

![[Screenshot_2023-02-19_at_11.27.39_AM.png]]